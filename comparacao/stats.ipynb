{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de diferenças salvo em comparacao.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def read_conllu_file(conllu_file):\n",
    "    sentences = defaultdict(list)\n",
    "    current_id = None\n",
    "\n",
    "    with open(conllu_file, 'r', encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# sent_id = \"):\n",
    "                current_id = line.replace(\"# sent_id = \", \"\")\n",
    "                # Remover o primeiro \"dante_01_\" se duplicado\n",
    "                if current_id.count(\"dante_01_\") > 1:\n",
    "                    current_id = current_id.replace(\"dante_01_\", \"\", 1)\n",
    "            elif line.startswith(\"#\"):\n",
    "                continue\n",
    "            elif line == \"\":\n",
    "                current_id = None\n",
    "            else:\n",
    "                if current_id is not None:\n",
    "                    parts = line.split(\"\\t\")\n",
    "                    if len(parts) > 1:\n",
    "                        sentences[current_id].append(parts[1])\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def compare_tokenizations(file1, file2, report_file):\n",
    "    tokens1 = read_conllu_file(file1)\n",
    "    tokens2 = read_conllu_file(file2)\n",
    "    \n",
    "    differences = []\n",
    "\n",
    "    all_ids = set(tokens1.keys()).union(set(tokens2.keys()))\n",
    "\n",
    "    for id in all_ids:\n",
    "        tokens_seq1 = tokens1.get(id, [])\n",
    "        tokens_seq2 = tokens2.get(id, [])\n",
    "        \n",
    "        if tokens_seq1 != tokens_seq2:\n",
    "            differences.append({\n",
    "                'ID': id,\n",
    "                'File1 Tokens': ' '.join(tokens_seq1),\n",
    "                'File2 Tokens': ' '.join(tokens_seq2)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(differences)\n",
    "    df.to_csv(report_file, index=False)\n",
    "    print(f\"Relatório de diferenças salvo em {report_file}\")\n",
    "\n",
    "# Caminhos dos arquivos conllu e do relatório\n",
    "conllu_file1 = r'C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1_reconstruido.conllu'  # Substitua pelo caminho do seu arquivo\n",
    "conllu_file2 = r'C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1.conllu'  # Substitua pelo caminho do seu arquivo\n",
    "report_file = r'comparacao.csv'\n",
    "\n",
    "# Comparar as tokenizações e gerar o relatório\n",
    "compare_tokenizations(conllu_file1, conllu_file2, report_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório HTML salvo em comparacao.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_differences(seq1, seq2):\n",
    "    \"\"\"Encontra as diferenças entre duas sequências de tokens\"\"\"\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    diferentes_seq1 = set()\n",
    "    diferentes_seq2 = set()\n",
    "    \n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag != 'equal':  # se não são iguais, marca os tokens como diferentes\n",
    "            diferentes_seq1.update(range(i1, i2))\n",
    "            diferentes_seq2.update(range(j1, j2))\n",
    "            \n",
    "    return diferentes_seq1, diferentes_seq2\n",
    "\n",
    "def create_comparison_report(csv_file, html_report_file):\n",
    "    # Carregar o CSV gerado previamente\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Renomear as colunas\n",
    "    df = df.rename(columns={'File1 Tokens': 'Dante Reconstruido', 'File2 Tokens': 'Dante Original'})\n",
    "    df['Dante Reconstruido'] = df['Dante Reconstruido'].fillna('').astype(str)\n",
    "    df['Dante Original'] = df['Dante Original'].fillna('').astype(str)\n",
    "\n",
    "    # Template HTML permanece o mesmo...\n",
    "    html_template = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"pt-BR\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Relatório de Comparação de Tokenização</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                line-height: 1.6;\n",
    "            }\n",
    "            table {\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin-top: 20px;\n",
    "            }\n",
    "            th, td {\n",
    "                padding: 12px;\n",
    "                border: 1px solid #ddd;\n",
    "                text-align: left;\n",
    "                vertical-align: top;\n",
    "            }\n",
    "            th {\n",
    "                background-color: #f4f4f4;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            tr:nth-child(even) {\n",
    "                background-color: #f9f9f9;\n",
    "            }\n",
    "            .diff {\n",
    "                background-color: #ffcccc;\n",
    "                padding: 2px 4px;\n",
    "                border-radius: 3px;\n",
    "            }\n",
    "            .token {\n",
    "                margin: 0 2px;\n",
    "            }\n",
    "            h1 {\n",
    "                color: #333;\n",
    "                border-bottom: 2px solid #333;\n",
    "                padding-bottom: 10px;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Relatório de Comparação de Tokenização</h1>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>ID</th>\n",
    "                    <th>Dante Reconstruido</th>\n",
    "                    <th>Dante Original</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                {% for row in rows %}\n",
    "                <tr>\n",
    "                    <td>{{ row.ID }}</td>\n",
    "                    <td>{{ row.Dante_Reconstruido | safe }}</td>\n",
    "                    <td>{{ row.Dante_Original | safe }}</td>\n",
    "                </tr>\n",
    "                {% endfor %}\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparar os dados para o template com comparação melhorada\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Dividir os tokens\n",
    "        dante_reconstruido_tokens = row['Dante Reconstruido'].split()\n",
    "        dante_original_tokens = row['Dante Original'].split()\n",
    "\n",
    "        # Encontrar as diferenças usando SequenceMatcher\n",
    "        diferentes_reconstruido, diferentes_original = find_differences(\n",
    "            dante_reconstruido_tokens, \n",
    "            dante_original_tokens\n",
    "        )\n",
    "\n",
    "        # Marcar apenas as diferenças\n",
    "        dante_reconstruido_tokens_str = \" \".join([\n",
    "            f\"<span class='diff token'>{token}</span>\" if i in diferentes_reconstruido \n",
    "            else f\"<span class='token'>{token}</span>\" \n",
    "            for i, token in enumerate(dante_reconstruido_tokens)\n",
    "        ])\n",
    "        \n",
    "        dante_original_tokens_str = \" \".join([\n",
    "            f\"<span class='diff token'>{token}</span>\" if i in diferentes_original \n",
    "            else f\"<span class='token'>{token}</span>\" \n",
    "            for i, token in enumerate(dante_original_tokens)\n",
    "        ])\n",
    "\n",
    "        rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'Dante_Reconstruido': dante_reconstruido_tokens_str,\n",
    "            'Dante_Original': dante_original_tokens_str\n",
    "        })\n",
    "\n",
    "    # Renderizar o template com os dados\n",
    "    template = Template(html_template)\n",
    "    html_content = template.render(rows=rows)\n",
    "\n",
    "    # Salvar o relatório HTML\n",
    "    with open(html_report_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"Relatório HTML salvo em {html_report_file}\")\n",
    "\n",
    "# Caminhos do arquivo CSV e do relatório HTML\n",
    "csv_file = r'comparacao.csv'\n",
    "html_report_file = r'comparacao.html'\n",
    "\n",
    "# Criar o relatório HTML\n",
    "create_comparison_report(csv_file, html_report_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
