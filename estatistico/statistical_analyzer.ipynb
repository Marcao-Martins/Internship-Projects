{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from conllu import parse\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats  # Adicionar esta linha\n",
    "from scipy.spatial.distance import jensenshannon  # Add this import\n",
    "from matplotlib.ticker import MultipleLocator  # Adicionar esta linha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug do parsing de C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1.conllu:\n",
      "Total de sentenças: 4042\n",
      "Primeira sentença tem 22 tokens\n",
      "Primeiros 3 tokens da primeira sentença:\n",
      "Token 1: {'id': 1, 'form': 'Notas', 'lemma': 'nota', 'upos': 'NOUN', 'xpos': None, 'feats': {'Gender': 'Fem', 'Number': 'Plur'}, 'head': 10, 'deprel': 'parataxis', 'deps': None, 'misc': None}\n",
      "Token 2: {'id': 2, 'form': 'gerais', 'lemma': 'geral', 'upos': 'ADJ', 'xpos': None, 'feats': {'Number': 'Plur'}, 'head': 1, 'deprel': 'amod', 'deps': None, 'misc': None}\n",
      "Token 3: {'id': 3, 'form': 'A', 'lemma': 'o', 'upos': 'DET', 'xpos': None, 'feats': {'Definite': 'Def', 'Gender': 'Fem', 'Number': 'Sing', 'PronType': 'Art'}, 'head': 4, 'deprel': 'det', 'deps': None, 'misc': None}\n",
      "\n",
      "Debug do parsing de C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1_reconstruido.conllu:\n",
      "Total de sentenças: 4042\n",
      "Primeira sentença tem 22 tokens\n",
      "Primeiros 3 tokens da primeira sentença:\n",
      "Token 1: {'id': 1, 'form': 'Notas', 'lemma': '_', 'upos': 'PROPN', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n",
      "Token 2: {'id': 2, 'form': 'gerais', 'lemma': '_', 'upos': 'PUNCT', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n",
      "Token 3: {'id': 3, 'form': 'A', 'lemma': '_', 'upos': 'PUNCT', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n",
      "\n",
      "Debug do parsing de DANTES_Large_treated.conllu:\n",
      "Total de sentenças: 126653\n",
      "Primeira sentença tem 15 tokens\n",
      "Primeiros 3 tokens da primeira sentença:\n",
      "Token 1: {'id': 1, 'form': 'Gol', 'lemma': '_', 'upos': 'PROPN', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n",
      "Token 2: {'id': 2, 'form': 'implantará', 'lemma': '_', 'upos': 'VERB', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n",
      "Token 3: {'id': 3, 'form': 'centro', 'lemma': '_', 'upos': 'NOUN', 'xpos': None, 'feats': None, 'head': None, 'deprel': '_', 'deps': None, 'misc': None}\n"
     ]
    }
   ],
   "source": [
    "def parsear_conllu(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as file:\n",
    "        # Lê todo o conteúdo do arquivo de uma vez\n",
    "        conteudo = file.read()\n",
    "    \n",
    "    try:\n",
    "        # Parse todo o conteúdo como um único bloco\n",
    "        dados = parse(conteudo)\n",
    "        \n",
    "        # Debug para verificar a estrutura\n",
    "        if len(dados) > 0:\n",
    "            primeira_sentenca = dados[0]\n",
    "            print(f\"\\nDebug do parsing de {caminho_arquivo}:\")\n",
    "            print(f\"Total de sentenças: {len(dados)}\")\n",
    "            print(f\"Primeira sentença tem {len(primeira_sentenca)} tokens\")\n",
    "            print(\"Primeiros 3 tokens da primeira sentença:\")\n",
    "            for i, token in enumerate(primeira_sentenca[:3]):\n",
    "                print(f\"Token {i+1}: {dict(token)}\")\n",
    "        \n",
    "        return dados\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao fazer parsing do arquivo {caminho_arquivo}\")\n",
    "        print(f\"Detalhes do erro: {e}\")\n",
    "        raise\n",
    "\n",
    "# Exemplo de uso\n",
    "caminho_arquivo1 = r'C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1.conllu'\n",
    "caminho_arquivo2 = r'C:\\Users\\Marcos\\Desktop\\tic\\bases\\DANTEStocksV2.1_reconstruido.conllu'\n",
    "caminho_arquivo3 = r'DANTES_Large_treated.conllu'\n",
    "\n",
    "# Parseia o conteúdo dos arquivos\n",
    "dados_conllu1 = parsear_conllu(caminho_arquivo1)\n",
    "dados_conllu2 = parsear_conllu(caminho_arquivo2)\n",
    "dados_conllu3 = parsear_conllu(caminho_arquivo3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar no início do arquivo, após os imports\n",
    "Dantes_Automatizado = \"DanteStocks Automatizado\"\n",
    "Dantes_Large = \"DanteStocks Large\"\n",
    "Dantes_Manual = \"DanteStocks Manual\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_tags_por_sentenca(corpora_data, nomes_corpora, caminho_grafico_tags, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Análise de tags por sentença para múltiplos corpora (até 4)\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores = ['skyblue', 'lightcoral', 'lightgreen', 'plum']\n",
    "    \n",
    "    # Coletar número de tags por bloco de texto para cada corpus\n",
    "    tags_por_bloco = []\n",
    "    stats = []\n",
    "    for corpus in corpora_data:\n",
    "        tags = [len(sentence) for sentence in corpus]\n",
    "        tags_por_bloco.append(tags)\n",
    "        stats.append({\n",
    "            'média': np.mean(tags),\n",
    "            'mediana': np.median(tags),\n",
    "            'desvio': np.std(tags),\n",
    "            'q1': np.percentile(tags, 25),\n",
    "            'q3': np.percentile(tags, 75),\n",
    "            'total_sentencas': len(tags)\n",
    "        })\n",
    "    \n",
    "    # Criar boxplots individuais\n",
    "    for i, (tags, nome, cor, stat) in enumerate(zip(tags_por_bloco, nomes_corpora, cores, stats)):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        bp = plt.boxplot(tags, patch_artist=True,\n",
    "                        boxprops=dict(facecolor=cor, alpha=0.7),\n",
    "                        medianprops=dict(color='red', linewidth=2),\n",
    "                        meanprops=dict(marker='D', markerfacecolor='darkblue', markersize=8),\n",
    "                        flierprops=dict(marker='o', markerfacecolor='gray', markersize=4, alpha=0.5),\n",
    "                        showmeans=True)\n",
    "        \n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.title(f'Distribuição - {nome}')\n",
    "        plt.ylabel('Número de Tags por Sentença')\n",
    "        \n",
    "        # Adicionar anotações com estatísticas\n",
    "        plt.text(0.95, 0.95, \n",
    "                f'Total de Sentenças: {stat[\"total_sentencas\"]:,}\\n'\n",
    "                f'Média: {stat[\"média\"]:.1f}\\nMediana: {stat[\"mediana\"]:.1f}\\n'\n",
    "                f'Desvio: {stat[\"desvio\"]:.1f}\\n'\n",
    "                f'Q1: {stat[\"q1\"]:.1f}\\nQ3: {stat[\"q3\"]:.1f}',\n",
    "                transform=plt.gca().transAxes, \n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{caminho_grafico_tags}_{i+1}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Criar gráfico comparativo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Preparar dados para o gráfico comparativo\n",
    "    metricas = ['Média', 'Mediana', 'Desvio']\n",
    "    valores = np.array([[s['média'], s['mediana'], s['desvio']] for s in stats])\n",
    "    \n",
    "    # Criar gráfico de barras agrupadas\n",
    "    x = np.arange(len(metricas))\n",
    "    width = 0.8 / len(corpora_data)\n",
    "    \n",
    "    for i, (nome, cor, vals) in enumerate(zip(nomes_corpora, cores, valores)):\n",
    "        pos = x + width * (i - (len(corpora_data)-1)/2)\n",
    "        bars = plt.bar(pos, vals, width, label=nome, color=cor, alpha=0.7)\n",
    "        \n",
    "        # Adicionar valores em cima das barras\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}',\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    plt.ylabel('Valor')\n",
    "    plt.title('Comparação de Estatísticas')\n",
    "    plt.xticks(x, metricas)\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{caminho_grafico_tags}_comparativo.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\section{Análise de Tags por Sentença}\\n\"\n",
    "        \"Esta seção apresenta uma análise da distribuição do número de tags por sentença \"\n",
    "        \"em cada corpus, permitindo comparar a complexidade estrutural das sentenças.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tabela de estatísticas\n",
    "    arquivo_latex.write(\"\\\\begin{table}[H]\\n\\\\centering\\n\")\n",
    "    arquivo_latex.write(\"\\\\begin{tabular}{|l|\" + \"c|\"*len(corpora_data) + \"}\\\\hline\\n\")\n",
    "    arquivo_latex.write(\"Métrica & \" + \" & \".join(nomes_corpora) + \" \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    metricas = [\n",
    "        ('Total de Sentenças', 'total_sentencas', '{:,}'),\n",
    "        ('Média', 'média', '{:.2f}'),\n",
    "        ('Mediana', 'mediana', '{:.2f}'),\n",
    "        ('Desvio Padrão', 'desvio', '{:.2f}'),\n",
    "        ('Primeiro Quartil (Q1)', 'q1', '{:.2f}'),\n",
    "        ('Terceiro Quartil (Q3)', 'q3', '{:.2f}')\n",
    "    ]\n",
    "    \n",
    "    for nome_metrica, chave, formato in metricas:\n",
    "        valores = [formato.format(stat[chave]) for stat in stats]\n",
    "        arquivo_latex.write(f\"{nome_metrica} & {' & '.join(valores)} \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Estatísticas do Número de Tags por Sentença}\\n\"\n",
    "        \"\\\\end{table}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Inserir os quatro gráficos\n",
    "    for i, nome in enumerate(nomes_corpora):\n",
    "        arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "            f\"{caminho_grafico_tags}_{i+1}.png\",\n",
    "            f\"Distribuição do Número de Tags por Sentença - {nome}\"\n",
    "        ))\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "        f\"{caminho_grafico_tags}_comparativo.png\",\n",
    "        \"Comparação de Estatísticas entre os Corpora\"\n",
    "    ))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return {\n",
    "        'estatisticas': stats,\n",
    "        'tags_por_bloco': tags_por_bloco\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_jensen_shannon(corpora_data, nomes_corpora, caminho_grafico, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Análise de distribuições usando Jensen-Shannon distance para múltiplos corpora (até 4)\n",
    "    \n",
    "    Args:\n",
    "        corpora_data: Lista de corpora para análise\n",
    "        nomes_corpora: Lista com os nomes dos corpora\n",
    "        caminho_grafico: Caminho para salvar o gráfico\n",
    "        arquivo_latex: Arquivo para escrita do relatório LaTeX\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores = ['lightblue', 'lightcoral', 'lightgreen', 'plum']\n",
    "    \n",
    "    # Calcular frequências relativas para cada corpus\n",
    "    pos_counters = []\n",
    "    totals = []\n",
    "    for corpus in corpora_data:\n",
    "        counter = Counter(token['upos'] for sentence in corpus for token in sentence if token['upos'])\n",
    "        pos_counters.append(counter)\n",
    "        totals.append(sum(counter.values()))\n",
    "    \n",
    "    # Obter todas as tags únicas\n",
    "    pos_tags = sorted(set().union(*[set(counter.keys()) for counter in pos_counters]))\n",
    "    \n",
    "    # Calcular distribuições de probabilidade\n",
    "    distributions = []\n",
    "    for counter, total in zip(pos_counters, totals):\n",
    "        freq_rel = {tag: counter.get(tag, 0)/total for tag in pos_tags}\n",
    "        distributions.append(np.array([freq_rel[tag] for tag in pos_tags]))\n",
    "    \n",
    "    # Calcular distâncias JS entre todos os pares\n",
    "    js_results = []\n",
    "    for i in range(len(distributions)):\n",
    "        for j in range(i+1, len(distributions)):\n",
    "            js_distance = jensenshannon(distributions[i], distributions[j])\n",
    "            js_divergence = js_distance ** 2\n",
    "            js_results.append({\n",
    "                'corpus1': nomes_corpora[i],\n",
    "                'corpus2': nomes_corpora[j],\n",
    "                'distance': js_distance,\n",
    "                'divergence': js_divergence\n",
    "            })\n",
    "    \n",
    "    # Criar visualização\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Gráfico de barras lado a lado\n",
    "    x = np.arange(len(pos_tags))\n",
    "    width = 0.8 / len(distributions)  # Ajusta largura baseado no número de corpora\n",
    "    \n",
    "    for i, (dist, nome, cor) in enumerate(zip(distributions, nomes_corpora, cores)):\n",
    "        position = x + width * (i - (len(distributions)-1)/2)\n",
    "        plt.bar(position, dist * 100, width, label=nome, color=cor, alpha=0.8)\n",
    "    \n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.title('Distribuição de Classes Gramaticais e Divergência de Jensen-Shannon', fontsize=14, pad=20)\n",
    "    plt.xlabel('Classes Gramaticais', fontsize=12)\n",
    "    plt.ylabel('Porcentagem (%)', fontsize=12)\n",
    "    plt.xticks(x, pos_tags, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Adicionar anotação com os valores das divergências\n",
    "    js_text = \"Distâncias JS:\\n\"\n",
    "    for result in js_results:\n",
    "        js_text += f\"{result['corpus1']} vs {result['corpus2']}:\\n\"\n",
    "        js_text += f\"Dist = {result['distance']:.4f}\\n\"\n",
    "        js_text += f\"Div = {result['divergence']:.4f}\\n\"\n",
    "    \n",
    "    plt.text(0.98, 0.98, js_text,\n",
    "             transform=plt.gca().transAxes, ha='right', va='top',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(caminho_grafico, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\section{Análise de Similaridade entre Distribuições}\\n\\n\"\n",
    "        \n",
    "        \"\\\\subsection{Introdução à Análise}\\n\"\n",
    "        \"Esta seção apresenta uma análise comparativa detalhada entre os corpora, utilizando métricas \"\n",
    "        \"estatísticas avançadas para quantificar suas semelhanças e diferenças. O foco principal está na \"\n",
    "        \"distribuição das Etiquetas POS (Part of Speech) em cada corpus.\\n\\n\"\n",
    "        \n",
    "        \"\\\\subsection{Metodologia: Distância de Jensen-Shannon}\\n\"\n",
    "        \"A análise utiliza a Distância de Jensen-Shannon (JS), uma métrica estatística sofisticada que:\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "        \"\\\\item Mede o grau de similaridade entre duas distribuições de probabilidade\\n\"\n",
    "        \"\\\\item Produz valores entre 0 e 1, onde:\\n\"\n",
    "        \"  \\\\begin{itemize}\\n\"\n",
    "        \"  \\\\item 0 indica distribuições idênticas\\n\"\n",
    "        \"  \\\\item 1 indica distribuições completamente diferentes\\n\"\n",
    "        \"  \\\\end{itemize}\\n\"\n",
    "        \"\\\\item É mais robusta que medidas simples como diferença percentual\\n\"\n",
    "        \"\\\\end{itemize}\\n\\n\"\n",
    "        \n",
    "        \"\\\\subsection{Resultados das Comparações}\\n\"\n",
    "    )\n",
    "    \n",
    "    # Adicionar tabela de resultados\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\begin{table}[H]\\n\\\\centering\\n\"\n",
    "        \"\\\\begin{tabular}{|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "        \"\\\\textbf{Corpus 1} & \\\\textbf{Corpus 2} & \\\\textbf{Distância JS} & \\\\textbf{Divergência JS} \\\\\\\\ \\\\hline\\n\"\n",
    "    )\n",
    "    \n",
    "    for result in js_results:\n",
    "        arquivo_latex.write(\n",
    "            f\"{result['corpus1']} & {result['corpus2']} & \"\n",
    "            f\"{result['distance']:.4f} & {result['divergence']:.4f} \\\\\\\\ \\\\hline\\n\"\n",
    "        )\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\end{tabular}\\n\\\\caption{Resultados da Análise de Jensen-Shannon}\\n\\\\end{table}\\n\\n\")\n",
    "    \n",
    "    # Adicionar interpretações para cada par\n",
    "    arquivo_latex.write(\"\\\\subsection{Interpretação dos Resultados}\\n\")\n",
    "    for result in js_results:\n",
    "        if result['distance'] < 0.1:\n",
    "            interpretacao = \"muito similares, sugerindo uma forte consistência no uso de classes gramaticais\"\n",
    "        elif result['distance'] < 0.2:\n",
    "            interpretacao = \"moderadamente similares, com algumas variações sutis no uso de classes gramaticais\"\n",
    "        elif result['distance'] < 0.3:\n",
    "            interpretacao = \"moderadamente diferentes, indicando variações significativas no uso de classes gramaticais\"\n",
    "        else:\n",
    "            interpretacao = \"substancialmente diferentes, demonstrando padrões distintos no uso de classes gramaticais\"\n",
    "        \n",
    "        arquivo_latex.write(\n",
    "            f\"\\\\textbf{{{result['corpus1']} vs {result['corpus2']}:}} Os corpora são {interpretacao}.\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Visualização dos Resultados}\\n\"\n",
    "        \"O gráfico abaixo apresenta uma comparação visual das distribuições de classes gramaticais \"\n",
    "        \"entre todos os corpora analisados.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(caminho_grafico, \n",
    "        \"Distribuição de Classes Gramaticais e Divergência de Jensen-Shannon\"))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "\n",
    "    return js_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_ks(corpora_data, nomes_corpora, caminho_grafico, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Realiza o teste Kolmogorov-Smirnov para comparar as distribuições de POS tags entre múltiplos corpora.\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores = ['coral', 'turquoise', 'lightgreen', 'plum']\n",
    "    \n",
    "    # Contagem de POS tags para cada corpus\n",
    "    def contar_pos_tags(corpus):\n",
    "        contador = Counter()\n",
    "        total_tokens = 0\n",
    "        for sentence in corpus:\n",
    "            for token in sentence:\n",
    "                if token['upostag']:\n",
    "                    contador[token['upostag']] += 1\n",
    "                    total_tokens += 1\n",
    "        return contador, total_tokens\n",
    "\n",
    "    # Coletar dados para todos os corpora\n",
    "    pos_counters = []\n",
    "    totals = []\n",
    "    for corpus in corpora_data:\n",
    "        counter, total = contar_pos_tags(corpus)\n",
    "        pos_counters.append(counter)\n",
    "        totals.append(total)\n",
    "    \n",
    "    # Obter todas as tags únicas e ordenadas\n",
    "    pos_tags = sorted(set().union(*[set(counter.keys()) for counter in pos_counters]))\n",
    "    \n",
    "    # Configurar estilo seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"Set2\")\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    \n",
    "    # Calcular frequências normalizadas para cada corpus\n",
    "    frequencies = []\n",
    "    cum_frequencies = []\n",
    "    for counter, total in zip(pos_counters, totals):\n",
    "        freq = np.array([counter.get(pos, 0)/total for pos in pos_tags])\n",
    "        frequencies.append(freq)\n",
    "        cum_frequencies.append(np.cumsum(freq) * 100)\n",
    "    \n",
    "    # População cumulativa\n",
    "    cum_pop = np.linspace(0, 100, len(pos_tags))\n",
    "    \n",
    "    # Realizar testes KS entre todos os pares\n",
    "    ks_results = []\n",
    "    for i in range(len(frequencies)):\n",
    "        for j in range(i+1, len(frequencies)):\n",
    "            estatistica, p_valor = stats.ks_2samp(frequencies[i], frequencies[j])\n",
    "            ks_results.append({\n",
    "                'corpus1': nomes_corpora[i],\n",
    "                'corpus2': nomes_corpora[j],\n",
    "                'estatistica': estatistica,\n",
    "                'p_valor': p_valor,\n",
    "                'cum_freq1': cum_frequencies[i],\n",
    "                'cum_freq2': cum_frequencies[j],\n",
    "                'cor1': cores[i],\n",
    "                'cor2': cores[j]\n",
    "            })\n",
    "    \n",
    "    # Criar figura para cada comparação\n",
    "    for idx, result in enumerate(ks_results):\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        \n",
    "        # Plotar linhas cumulativas\n",
    "        ax.plot(cum_pop, result['cum_freq1'], \n",
    "               '-o', color=result['cor1'], label=result['corpus1'],\n",
    "               markersize=8, alpha=0.7, linewidth=2)\n",
    "        ax.plot(cum_pop, result['cum_freq2'], \n",
    "               '-o', color=result['cor2'], label=result['corpus2'],\n",
    "               markersize=8, alpha=0.7, linewidth=2)\n",
    "        \n",
    "        # Encontrar ponto de máxima diferença\n",
    "        diff = np.abs(result['cum_freq1'] - result['cum_freq2'])\n",
    "        max_diff_idx = np.argmax(diff)\n",
    "        \n",
    "        # Plotar linha vertical KS\n",
    "        ks_x = cum_pop[max_diff_idx]\n",
    "        ks_y1 = result['cum_freq1'][max_diff_idx]\n",
    "        ks_y2 = result['cum_freq2'][max_diff_idx]\n",
    "        ax.vlines(x=ks_x, ymin=min(ks_y1, ks_y2), ymax=max(ks_y1, ks_y2),\n",
    "                 color='black', linewidth=2, linestyle='--',\n",
    "                 label='Distância KS')\n",
    "        \n",
    "        # Adicionar texto KS\n",
    "        ax.text(ks_x + 2, np.mean([ks_y1, ks_y2]),\n",
    "               f'Distância KS: {result[\"estatistica\"]:.5%}\\np-valor: {result[\"p_valor\"]:.5f}',\n",
    "               verticalalignment='center',\n",
    "               bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "        \n",
    "        # Configurar gráfico\n",
    "        ax.set_title(f'Teste de Kolmogorov-Smirnov:\\n'\n",
    "                    f'Comparação entre {result[\"corpus1\"]} e {result[\"corpus2\"]}',\n",
    "                    fontsize=14, pad=20)\n",
    "        ax.set_xlabel('População Cumulativa (%)', fontsize=12)\n",
    "        ax.set_ylabel('Frequência Cumulativa (%)', fontsize=12)\n",
    "        \n",
    "        # Configurar eixos\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}%'))\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}%'))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.set_xlim(-5, 105)\n",
    "        \n",
    "        # Adicionar interpretação\n",
    "        interpretacao = \"Interpretação do Teste:\\n\"\n",
    "        if result['p_valor'] < 0.05:\n",
    "            interpretacao += \"Distribuições significativamente diferentes\"\n",
    "        else:\n",
    "            interpretacao += \"Distribuições estatisticamente similares\"\n",
    "        \n",
    "        ax.text(0.02, 0.02, interpretacao,\n",
    "                transform=ax.transAxes,\n",
    "                bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "        \n",
    "        # Ajustar legenda e layout\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n",
    "                 title='Corpora Comparados')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salvar gráfico\n",
    "        caminho = f\"{caminho_grafico[:-4]}_{idx+1}.png\"\n",
    "        plt.savefig(caminho, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\section{Teste de Kolmogorov-Smirnov (KS)}\\n\\n\"\n",
    "        \n",
    "        \"\\\\subsection{Introdução ao Teste KS}\\n\"\n",
    "        \"O teste de Kolmogorov-Smirnov é um teste estatístico não-paramétrico que avalia se duas amostras \"\n",
    "        \"provêm da mesma distribuição. Este teste é particularmente útil para comparar distribuições de \"\n",
    "        \"frequência de classes gramaticais entre diferentes corpora.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tabela de resultados - Versão corrigida\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Resultados das Comparações}\\n\"\n",
    "        \"\\\\begin{table}[H]\\n\"\n",
    "        \"\\\\small\\n\"  # Reduz o tamanho da fonte\n",
    "        \"\\\\setlength{\\\\tabcolsep}{5pt}\\n\"  # Ajusta o espaçamento entre colunas\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\begin{tabular}{|l|c|c|l|}\\n\\\\hline\\n\"  # 'l' para alinhar texto à esquerda\n",
    "        \"\\\\textbf{Comparação} & \"\n",
    "        \"\\\\textbf{\\\\begin{tabular}[c]{@{}c@{}}Estatística\\\\\\\\KS\\\\end{tabular}} & \"\n",
    "        \"\\\\textbf{P-valor} & \"\n",
    "        \"\\\\textbf{Interpretação} \\\\\\\\ \\\\hline\\n\"\n",
    "    )\n",
    "    \n",
    "    for result in ks_results:\n",
    "        interpretacao = \"Significativamente diferentes\" if result['p_valor'] < 0.05 else \"Estatisticamente similares\"\n",
    "        arquivo_latex.write(\n",
    "            f\"{result['corpus1']} vs {result['corpus2']} & \"\n",
    "            f\"{result['estatistica']:.4f} & \"\n",
    "            f\"{result['p_valor']:.5f} & \"\n",
    "            f\"{interpretacao} \\\\\\\\ \\\\hline\\n\"\n",
    "        )\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Resultados dos Testes de Kolmogorov-Smirnov}\\n\"\n",
    "        \"\\\\end{table}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Adicionar gráficos\n",
    "    for idx in range(len(ks_results)):\n",
    "        caminho = f\"{caminho_grafico[:-4]}_{idx+1}.png\"\n",
    "        arquivo_latex.write(salvar_grafico_e_gerar_latex(caminho, \n",
    "            f\"Comparação KS: {ks_results[idx]['corpus1']} vs {ks_results[idx]['corpus2']}\"))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return ks_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_diversidade_lexical(corpora_data, nomes_corpora, caminho_grafico_base, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Realiza uma análise comparativa da diversidade lexical entre múltiplos corpora (até 4).\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores_pie = [\n",
    "        ['skyblue', 'lightblue', 'powderblue'],\n",
    "        ['lightcoral', 'indianred', 'rosybrown'],\n",
    "        ['lightgreen', 'mediumseagreen', 'darkseagreen'],\n",
    "        ['plum', 'orchid', 'thistle']\n",
    "    ]\n",
    "    cores_bar = ['skyblue', 'lightcoral', 'lightgreen', 'plum']\n",
    "    \n",
    "    def calcular_metricas(conllu_data):\n",
    "        tokens = [token['form'].lower() for sentence in conllu_data for token in sentence]\n",
    "        types = set(tokens)\n",
    "        token_counter = Counter(tokens)\n",
    "        total_tokens = len(tokens)\n",
    "        total_types = len(types)\n",
    "        hapax_legomena = sum(1 for freq in token_counter.values() if freq == 1)\n",
    "        dis_legomena = sum(1 for freq in token_counter.values() if freq == 2)\n",
    "        ttr = total_types / total_tokens\n",
    "        return {\n",
    "            'tokens': tokens,\n",
    "            'types': types,\n",
    "            'total_tokens': total_tokens,\n",
    "            'total_types': total_types,\n",
    "            'hapax': hapax_legomena,\n",
    "            'dis': dis_legomena,\n",
    "            'ttr': ttr,\n",
    "            'counter': token_counter\n",
    "        }\n",
    "    \n",
    "    # Calcular métricas para todos os corpora\n",
    "    metricas = [calcular_metricas(corpus) for corpus in corpora_data]\n",
    "    \n",
    "    # Configurações gerais\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    \n",
    "    # Gráfico 1: Comparação de métricas principais (gráficos de pizza)\n",
    "    n_corpora = len(corpora_data)\n",
    "    fig, axes = plt.subplots(1, n_corpora, figsize=(6*n_corpora, 6))\n",
    "    if n_corpora == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    metrics = ['Hapax\\nLegomena', 'Dis\\nLegomena', 'Outros\\nTypes']\n",
    "    \n",
    "    for i, (metrica, ax, nome) in enumerate(zip(metricas, axes, nomes_corpora)):\n",
    "        values = [\n",
    "            metrica['hapax']/metrica['total_tokens']*100,\n",
    "            metrica['dis']/metrica['total_tokens']*100,\n",
    "            (metrica['total_tokens'] - metrica['hapax'] - metrica['dis'])/metrica['total_tokens']*100\n",
    "        ]\n",
    "        \n",
    "        wedges, _, _ = ax.pie(values, labels=None, autopct='', colors=cores_pie[i])\n",
    "        ax.set_title(f'Distribuição - {nome}')\n",
    "        \n",
    "        # Legendas com porcentagens\n",
    "        legend_labels = [f'{m} ({v:.1f}%)' for m, v in zip(metrics, values)]\n",
    "        ax.legend(wedges, legend_labels, title=\"Métricas\",\n",
    "                 loc=\"center left\", bbox_to_anchor=(1, 0, -0.2, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{caminho_grafico_base}_metricas.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Gráfico 2: Type-Token Ratio\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ttr_data = [[nome, metrica['ttr']] for nome, metrica in zip(nomes_corpora, metricas)]\n",
    "    sns.barplot(x=[d[0] for d in ttr_data], y=[d[1] for d in ttr_data], \n",
    "               palette=cores_bar[:len(corpora_data)])\n",
    "    plt.title('Type-Token Ratio (TTR)')\n",
    "    plt.ylabel('TTR')\n",
    "    \n",
    "    for i, (_, v) in enumerate(ttr_data):\n",
    "        plt.text(i, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{caminho_grafico_base}_ttr.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\section{Análise Comparativa de Diversidade Lexical}\\n\"\n",
    "        \"Esta seção apresenta uma análise detalhada da diversidade lexical dos corpora, \"\n",
    "        \"comparando diferentes métricas e distribuições entre os textos.\\n\\n\"\n",
    "        \n",
    "        \"\\\\subsection{Métricas Principais}\\n\"\n",
    "        \"As métricas a seguir nos permitem quantificar diferentes aspectos do uso do vocabulário:\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Métricas para cada corpus\n",
    "    for nome, metrica in zip(nomes_corpora, metricas):\n",
    "        arquivo_latex.write(\n",
    "            f\"\\\\textbf{{{nome}}}:\\n\"\n",
    "            \"\\\\begin{itemize}\\n\"\n",
    "            f\"\\\\item Total de Tokens: {metrica['total_tokens']:,}\\n\"\n",
    "            f\"\\\\item Total de Types: {metrica['total_types']:,}\\n\"\n",
    "            f\"\\\\item Hapax Legomena: {metrica['hapax']:,} \"\n",
    "            f\"({metrica['hapax']/metrica['total_tokens']*100:.1f}\\\\%)\\n\"\n",
    "            f\"\\\\item Dis Legomena: {metrica['dis']:,} \"\n",
    "            f\"({metrica['dis']/metrica['total_tokens']*100:.1f}\\\\%)\\n\"\n",
    "            f\"\\\\item Type-Token Ratio (TTR): {metrica['ttr']:.3f}\\n\"\n",
    "            \"\\\\end{itemize}\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    # Análise comparativa\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Análise Comparativa}\\n\"\n",
    "        \"Comparando os corpora, observamos:\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "    )\n",
    "    \n",
    "    # Encontrar corpus com maior TTR\n",
    "    max_ttr_idx = max(range(len(metricas)), key=lambda i: metricas[i]['ttr'])\n",
    "    arquivo_latex.write(\n",
    "        f\"\\\\item {nomes_corpora[max_ttr_idx]} apresenta a maior diversidade lexical \"\n",
    "        f\"(TTR = {metricas[max_ttr_idx]['ttr']:.3f})\\n\"\n",
    "    )\n",
    "    \n",
    "    # Comparar tamanhos\n",
    "    sizes = [f\"{m['total_tokens']:,}\" for m in metricas]\n",
    "    arquivo_latex.write(\n",
    "        f\"\\\\item Tamanhos dos corpora: {', '.join(sizes)} tokens\\n\"\n",
    "    )\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\end{itemize}\\n\\n\")\n",
    "    \n",
    "    # Análise dos gráficos\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Análise dos Gráficos}\\n\\n\"\n",
    "        \"\\\\textbf{1. Comparação de Métricas de Diversidade:}\\n\"\n",
    "        \"Os gráficos de pizza mostram a distribuição de:\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "        \"\\\\item Hapax Legomena: Palavras que aparecem uma única vez\\n\"\n",
    "        \"\\\\item Dis Legomena: Palavras que aparecem duas vezes\\n\"\n",
    "        \"\\\\item Outras palavras únicas: Types que aparecem três ou mais vezes\\n\"\n",
    "        \"\\\\end{itemize}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(f\"{caminho_grafico_base}_metricas.png\", \n",
    "        \"Comparação de Métricas de Diversidade\"))\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\textbf{2. Type-Token Ratio (TTR):}\\n\"\n",
    "        \"O gráfico de barras compara o TTR entre os corpora, onde valores mais altos \"\n",
    "        \"indicam maior diversidade lexical.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(f\"{caminho_grafico_base}_ttr.png\", \n",
    "        \"Type-Token Ratio (TTR)\"))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcos\\AppData\\Local\\Temp\\ipykernel_23692\\2913429422.py:77: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[d[0] for d in ttr_data], y=[d[1] for d in ttr_data],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório LaTeX salvo como relatorio_comparativo.tex.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Função para salvar gráficos e gerar comandos LaTeX para inseri-los\n",
    "def salvar_grafico_e_gerar_latex(caminho_grafico, titulo_grafico):\n",
    "    return f\"\"\"\n",
    "    \\\\begin{{figure}}[H]\n",
    "        \\\\centering\n",
    "        \\\\includegraphics[width=1.0\\\\textwidth]{{{caminho_grafico}}}\n",
    "        \\\\caption{{{titulo_grafico}}}\n",
    "    \\\\end{{figure}}\n",
    "    \"\"\"\n",
    "\n",
    "def analise_frequencia_pos(corpora_data, nomes_corpora, caminho_grafico_base, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Análise de frequência de POS tags para múltiplos corpora (até 4)\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores = ['skyblue', 'lightcoral', 'lightgreen', 'plum']\n",
    "    \n",
    "    # Coletar contagens para todos os corpora\n",
    "    pos_counters = []\n",
    "    total_tags = []\n",
    "    for corpus in corpora_data:\n",
    "        counter = Counter(token['upostag'] for sentence in corpus \n",
    "                        for token in sentence if token['upostag'] is not None)\n",
    "        pos_counters.append(counter)\n",
    "        total_tags.append(sum(counter.values()))\n",
    "    \n",
    "    # Obter todas as tags únicas\n",
    "    pos_tags = sorted(set().union(*[set(counter.keys()) for counter in pos_counters]))\n",
    "    \n",
    "    # Calcular frequências e porcentagens\n",
    "    frequencias = []\n",
    "    porcentagens = []\n",
    "    for counter, total in zip(pos_counters, total_tags):\n",
    "        freq = [counter.get(tag, 0) for tag in pos_tags]\n",
    "        frequencias.append(freq)\n",
    "        porcentagens.append([(f / total) * 100 for f in freq])\n",
    "    \n",
    "    # Gráficos individuais de frequência\n",
    "    for i, (freq, nome) in enumerate(zip(frequencias, nomes_corpora)):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(pos_tags, freq, color=cores[i])\n",
    "        \n",
    "        # Adicionar valores em cima das barras\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height):,}',\n",
    "                    ha='center', va='bottom')\n",
    "            \n",
    "        plt.title(f'Distribuição de Frequência das Tags POS ({nome})')\n",
    "        plt.xlabel('Tags POS')\n",
    "        plt.ylabel('Frequência')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{caminho_grafico_base}_{i+1}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # Gráfico comparativo das porcentagens\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    width = 0.8 / len(corpora_data)\n",
    "    for i, (perc, nome, cor) in enumerate(zip(porcentagens, nomes_corpora, cores)):\n",
    "        pos = [j + width * (i - (len(corpora_data)-1)/2) for j in range(len(pos_tags))]\n",
    "        plt.bar(pos, perc, width=width, label=nome, color=cor)\n",
    "    \n",
    "    plt.title('Comparação de Porcentagens das Tags POS')\n",
    "    plt.xlabel('Tags POS')\n",
    "    plt.ylabel('Porcentagem (%)')\n",
    "    plt.xticks(range(len(pos_tags)), pos_tags, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{caminho_grafico_base}_comparativo.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\"\\\\newpage\\n\\\\section{Análise de Frequência das Tags POS}\\n\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"As etiquetas POS (Part-of-Speech) são rótulos que identificam as características \"\n",
    "        \"linguísticas de cada palavra em um texto. Esta análise compara a distribuição \"\n",
    "        \"dessas classes gramaticais entre os corpora.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Índice de Tags POS\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection*{Índice de Tags POS}\\n\\n\"\n",
    "        \"As principais tags utilizadas na análise são:\\n\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "        \"    \\\\item \\\\textbf{ADJ} - Adjetivos\\n\"\n",
    "        \"    \\\\item \\\\textbf{ADP} - Preposições\\n\" \n",
    "        \"    \\\\item \\\\textbf{ADV} - Advérbios\\n\"\n",
    "        \"    \\\\item \\\\textbf{AUX} - Verbos Auxiliares\\n\"\n",
    "        \"    \\\\item \\\\textbf{CCONJ} - Conjunções Coordenativas\\n\"\n",
    "        \"    \\\\item \\\\textbf{DET} - Determinantes\\n\"\n",
    "        \"    \\\\item \\\\textbf{INTJ} - Interjeições\\n\"\n",
    "        \"    \\\\item \\\\textbf{NOUN} - Substantivos\\n\"\n",
    "        \"    \\\\item \\\\textbf{NUM} - Numerais\\n\"\n",
    "        \"    \\\\item \\\\textbf{PART} - Partículas\\n\"\n",
    "        \"    \\\\item \\\\textbf{PRON} - Pronomes\\n\"\n",
    "        \"    \\\\item \\\\textbf{PROPN} - Nomes Próprios\\n\"\n",
    "        \"    \\\\item \\\\textbf{PUNCT} - Pontuação\\n\"\n",
    "        \"    \\\\item \\\\textbf{SCONJ} - Conjunções Subordinativas\\n\"\n",
    "        \"    \\\\item \\\\textbf{SYM} - Símbolos\\n\"\n",
    "        \"    \\\\item \\\\textbf{VERB} - Verbos\\n\"\n",
    "        \"    \\\\item \\\\textbf{X} - Outros\\n\"\n",
    "        \"    \\\\item \\\\textbf{\\\\_} - Não Classificado\\n\"\n",
    "        \"\\\\end{itemize}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tabela de Frequências\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\begin{table}[H]\\n\"\n",
    "        \"\\\\scriptsize\\n\"  # Fonte ainda menor que \\small\n",
    "        \"\\\\setlength{\\\\tabcolsep}{3pt}\\n\"  # Espaçamento ainda menor entre colunas\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\begin{tabular}{|l|\" + \"r|\"*len(corpora_data) + \"}\\\\hline\\n\"\n",
    "        \"\\\\textbf{Tag} & \" +  # Encurtando o cabeçalho\n",
    "        \" & \".join([f\"\\\\textbf{{{nome}}}\" for nome in nomes_corpora]) +  # Remove \"Freq.\" do cabeçalho\n",
    "        \" \\\\\\\\ \\\\hline\\n\"\n",
    "    )\n",
    "    \n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        freqs = [f\"{int(freq[i]):,}\" for freq in frequencias]\n",
    "        arquivo_latex.write(f\"{tag} & {' & '.join(freqs)} \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Frequência das Tags POS por Corpus}\\n\"\n",
    "        \"\\\\end{table}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tabela de Porcentagens\n",
    "    arquivo_latex.write(\"\\\\begin{table}[H]\\n\\\\centering\\n\")\n",
    "    arquivo_latex.write(\"\\\\begin{tabular}{|c|\" + \"c|\"*len(corpora_data) + \"}\\\\hline\\n\")\n",
    "    arquivo_latex.write(\"Tag POS & \" + \" & \".join([f\"\\\\% {nome}\" for nome in nomes_corpora]) + \" \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        percs = [f\"{perc[i]:.2f}\\\\%\" for perc in porcentagens]\n",
    "        arquivo_latex.write(f\"{tag} & {' & '.join(percs)} \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\end{tabular}\\n\\\\caption{Porcentagem das Tags POS}\\n\\\\end{table}\\n\\n\")\n",
    "    \n",
    "    # Inserir gráficos\n",
    "    for i, nome in enumerate(nomes_corpora):\n",
    "        arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "            f\"{caminho_grafico_base}_{i+1}.png\",\n",
    "            f\"Distribuição de Frequência das Tags POS ({nome})\"\n",
    "        ))\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "        f\"{caminho_grafico_base}_comparativo.png\",\n",
    "        \"Comparação de Porcentagens das Tags POS\"\n",
    "    ))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return {\n",
    "        'frequencias': frequencias,\n",
    "        'porcentagens': porcentagens,\n",
    "        'tags': pos_tags\n",
    "    }\n",
    "\n",
    "def analise_comprimento_tokens(corpora_data, nomes_corpora, caminho_grafico_base, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Análise de comprimento dos tokens para múltiplos corpora (até 4)\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    # Cores para cada corpus\n",
    "    cores = ['#4FB6D6', '#FF6B6B', '#90EE90', '#DDA0DD']\n",
    "    \n",
    "    # Coletar comprimentos dos tokens para todos os corpora\n",
    "    token_lengths = []\n",
    "    total_tokens = []\n",
    "    for corpus in corpora_data:\n",
    "        lengths = [len(token['form']) for sentence in corpus for token in sentence]\n",
    "        token_lengths.append(lengths)\n",
    "        total_tokens.append(len(lengths))\n",
    "    \n",
    "    # Obter todos os comprimentos únicos\n",
    "    all_lengths = sorted(set().union(*[set(lengths) for lengths in token_lengths]))\n",
    "    \n",
    "    # Calcular frequências em porcentagem\n",
    "    freq_percents = []\n",
    "    for lengths, total in zip(token_lengths, total_tokens):\n",
    "        freq_percent = [(lengths.count(length) / total) * 100 for length in all_lengths]\n",
    "        freq_percents.append(freq_percent)\n",
    "    \n",
    "    # Estatísticas comparativas\n",
    "    estatisticas = []\n",
    "    for lengths in token_lengths:\n",
    "        estatisticas.append({\n",
    "            'media': np.mean(lengths),\n",
    "            'mediana': np.median(lengths),\n",
    "            'std': np.std(lengths)\n",
    "        })\n",
    "    \n",
    "    # Adicionar estatísticas no LaTeX\n",
    "    arquivo_latex.write(\"\\\\section{Análise de Comprimento dos Tokens}\\n\")\n",
    "    arquivo_latex.write(\n",
    "        \"O comprimento dos tokens é uma medida importante na análise linguística, \"\n",
    "        \"pois nos permite entender a distribuição do tamanho das palavras em um corpus. \"\n",
    "        \"Esta análise pode revelar padrões no uso de palavras curtas versus longas, \"\n",
    "        \"além de ajudar a identificar possíveis diferenças estilísticas entre os corpora.\\\\\\\\\\\\\\\\\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tabela de estatísticas\n",
    "    arquivo_latex.write(\"\\\\begin{table}[H]\\n\\\\centering\\n\")\n",
    "    arquivo_latex.write(\"\\\\begin{tabular}{|c|\" + \"c|\"*len(corpora_data) + \"}\\\\hline\\n\")\n",
    "    arquivo_latex.write(\"Métrica & \" + \" & \".join(nomes_corpora) + \" \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    metricas = ['Comprimento Médio', 'Mediana', 'Desvio Padrão']\n",
    "    for metrica in metricas:\n",
    "        if metrica == 'Comprimento Médio':\n",
    "            valores = [f\"{e['media']:.2f}\" for e in estatisticas]\n",
    "        elif metrica == 'Mediana':\n",
    "            valores = [f\"{e['mediana']:.2f}\" for e in estatisticas]\n",
    "        else:  # Desvio Padrão\n",
    "            valores = [f\"{e['std']:.2f}\" for e in estatisticas]\n",
    "        arquivo_latex.write(f\"{metrica} & {' & '.join(valores)} \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\end{tabular}\\n\\\\caption{Comparação do Comprimento dos Tokens}\\n\\\\end{table}\\n\\n\")\n",
    "    \n",
    "    # Filtrar comprimentos até 30 para os gráficos\n",
    "    max_length = 30\n",
    "    filtered_lengths = [l for l in all_lengths if l <= max_length]\n",
    "    filtered_freqs = []\n",
    "    for freqs in freq_percents:\n",
    "        filtered_freqs.append([f for l, f in zip(all_lengths, freqs) if l <= max_length])\n",
    "    \n",
    "    # Gráficos individuais\n",
    "    for i, (freqs, nome, cor) in enumerate(zip(filtered_freqs, nomes_corpora, cores)):\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.bar(filtered_lengths, freqs, color=cor, alpha=0.8)\n",
    "        plt.title(f'Distribuição do Comprimento dos Tokens ({nome})', fontsize=14, pad=20)\n",
    "        plt.xlabel('Comprimento dos Tokens', fontsize=12)\n",
    "        plt.ylabel('Frequência (%)', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(-0.5, max_length + 0.5)\n",
    "        plt.ylim(0, max(freqs) * 1.15)\n",
    "        \n",
    "        # Adiciona rótulos para valores significativos\n",
    "        for j, v in enumerate(freqs):\n",
    "            if v > 0.5:\n",
    "                plt.text(filtered_lengths[j], v, f'{v:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.xticks(filtered_lengths)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{caminho_grafico_base}_{i+1}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Gráfico comparativo\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    width = 0.8 / len(corpora_data)\n",
    "    x = np.arange(len(filtered_lengths))\n",
    "    \n",
    "    for i, (freqs, nome, cor) in enumerate(zip(filtered_freqs, nomes_corpora, cores)):\n",
    "        offset = width * (i - (len(corpora_data)-1)/2)\n",
    "        plt.bar(x + offset, freqs, width=width, label=nome, color=cor, alpha=0.8)\n",
    "    \n",
    "    plt.title('Comparação de Comprimento dos Tokens', fontsize=14, pad=20)\n",
    "    plt.xlabel('Comprimento dos Tokens', fontsize=12)\n",
    "    plt.ylabel('Frequência (%)', fontsize=12)\n",
    "    plt.xlim(-0.8, max(x) + 0.8)\n",
    "    plt.ylim(0, max([max(f) for f in filtered_freqs]) * 1.15)\n",
    "    \n",
    "    plt.xticks(x, filtered_lengths)\n",
    "    plt.legend(fontsize=10, framealpha=0.9, loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{caminho_grafico_base}_comparativo.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Inserir gráficos no LaTeX\n",
    "    for i, nome in enumerate(nomes_corpora):\n",
    "        arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "            f\"{caminho_grafico_base}_{i+1}.png\",\n",
    "            f\"Distribuição de Comprimento dos Tokens ({nome})\"\n",
    "        ))\n",
    "    \n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(\n",
    "        f\"{caminho_grafico_base}_comparativo.png\",\n",
    "        \"Comparação de Comprimento dos Tokens\"\n",
    "    ))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return {\n",
    "        'estatisticas': estatisticas,\n",
    "        'comprimentos': token_lengths,\n",
    "        'frequencias': freq_percents\n",
    "    }\n",
    "\n",
    "def analise_frequencia_por_sentenca(corpora_data, nomes_corpora, caminho_grafico_base, arquivo_latex):\n",
    "    \"\"\"\n",
    "    Análise de frequência por sentença para múltiplos corpora (até 4)\n",
    "    \"\"\"\n",
    "    if len(corpora_data) > 4:\n",
    "        raise ValueError(\"Esta função suporta no máximo 4 corpora\")\n",
    "    \n",
    "    if len(corpora_data) != len(nomes_corpora):\n",
    "        raise ValueError(\"O número de corpora deve ser igual ao número de nomes\")\n",
    "    \n",
    "    n_corpora = len(corpora_data)\n",
    "    cores = ['skyblue', 'lightcoral', 'lightgreen', 'plum']\n",
    "    \n",
    "    # Calcular tokens por sentença para todos os corpora\n",
    "    tokens_por_sentenca = []\n",
    "    stats = []\n",
    "    \n",
    "    for corpus in corpora_data:\n",
    "        tokens = [len(sentence) for sentence in corpus]\n",
    "        tokens_por_sentenca.append(tokens)\n",
    "        \n",
    "        stats.append({\n",
    "            'média': np.mean(tokens),\n",
    "            'mediana': np.median(tokens),\n",
    "            'desvio': np.std(tokens),\n",
    "            'mínimo': min(tokens),\n",
    "            'máximo': max(tokens),\n",
    "            'total_sentencas': len(tokens)\n",
    "        })\n",
    "    \n",
    "    # Criar subplots\n",
    "    fig, axes = plt.subplots(1, len(corpora_data), figsize=(6*len(corpora_data), 6))\n",
    "    if len(corpora_data) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Determinar bins fixos até 100\n",
    "    bins = np.linspace(0, 100, 50)\n",
    "    \n",
    "    # Criar histogramas\n",
    "    for i, (tokens, stat, nome, cor, ax) in enumerate(zip(tokens_por_sentenca, stats, nomes_corpora, cores, axes)):\n",
    "        # Filtrar tokens para mostrar apenas até 100\n",
    "        tokens_filtrados = [t for t in tokens if t <= 100]\n",
    "        \n",
    "        # Criar histograma com frequências relativas (em porcentagem)\n",
    "        n, _, _ = ax.hist(tokens_filtrados, bins=bins, alpha=0.7, color=cor, label=nome,\n",
    "                         weights=np.ones_like(tokens_filtrados) * 100 / len(tokens))\n",
    "        \n",
    "        # Adicionar linhas de média e mediana\n",
    "        if stat['média'] <= 100:\n",
    "            ax.axvline(stat['média'], color='blue', linestyle='dashed', \n",
    "                      label=f\"Média ({stat['média']:.1f})\")\n",
    "        if stat['mediana'] <= 100:\n",
    "            ax.axvline(stat['mediana'], color='darkblue', linestyle='dashed', \n",
    "                      label=f\"Mediana ({stat['mediana']:.1f})\")\n",
    "        \n",
    "        # Configurar rótulos e título\n",
    "        ax.set_title(f'Distribuição - {nome}')\n",
    "        ax.set_xlabel('Tokens por Sentença')\n",
    "        ax.set_ylabel('Frequência (%)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Fixar limites\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_ylim(0, 25)  # Ajuste este valor conforme necessário\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(caminho_grafico_base, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # Gerar relatório LaTeX\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\section{Análise Comparativa do Tamanho das Sentenças}\\n\"\n",
    "        \"Esta seção apresenta uma análise detalhada da distribuição do número de tokens \"\n",
    "        \"por sentença nos corpora. Esta métrica nos ajuda a entender a complexidade \"\n",
    "        \"estrutural das sentenças e as diferenças de estilo entre os textos.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "        # Tabela de estatísticas - Versão corrigida\n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Estatísticas Descritivas}\\n\"\n",
    "        \"\\\\begin{table}[H]\\n\"\n",
    "        \"\\\\small\\n\"  # Reduz o tamanho da fonte\n",
    "        \"\\\\setlength{\\\\tabcolsep}{5pt}\\n\"  # Ajusta o espaçamento entre colunas\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\begin{tabular}{|l|\" + \"r|\"*n_corpora + \"}\\\\hline\\n\"  # 'r' para alinhar números à direita\n",
    "        \"\\\\textbf{Métrica} & \" + \" & \".join([f\"\\\\textbf{{{nome}}}\" for nome in nomes_corpora]) + \n",
    "        \" \\\\\\\\ \\\\hline\\n\"\n",
    "    )\n",
    "    \n",
    "    metricas = [\n",
    "        ('Número de Sentenças', 'total_sentencas', '{:,}'),\n",
    "        ('Média de Tokens', 'média', '{:.2f}'),\n",
    "        ('Mediana', 'mediana', '{:.2f}'),\n",
    "        ('Desvio Padrão', 'desvio', '{:.2f}'),\n",
    "        ('Mínimo', 'mínimo', '{:d}'),\n",
    "        ('Máximo', 'máximo', '{:d}')\n",
    "    ]\n",
    "    \n",
    "    for nome_metrica, chave, formato in metricas:\n",
    "        valores = [formato.format(stat[chave]) for stat in stats]\n",
    "        arquivo_latex.write(f\"\\\\textbf{{{nome_metrica}}} & {' & '.join(valores)} \\\\\\\\ \\\\hline\\n\")\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Estatísticas do Tamanho das Sentenças}\\n\"\n",
    "        \"\\\\end{table}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Análise comparativa\n",
    "    arquivo_latex.write(\"\\\\subsection{Análise Comparativa}\\n\")\n",
    "    \n",
    "    # Encontrar corpus com maior média\n",
    "    max_media_idx = max(range(len(stats)), key=lambda i: stats[i]['média'])\n",
    "    arquivo_latex.write(\n",
    "        f\"{nomes_corpora[max_media_idx]} apresenta, em média, as sentenças mais longas \"\n",
    "        f\"({stats[max_media_idx]['média']:.1f} tokens por sentença).\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Encontrar corpus com maior variabilidade\n",
    "    max_desvio_idx = max(range(len(stats)), key=lambda i: stats[i]['desvio'])\n",
    "    arquivo_latex.write(\n",
    "        f\"{nomes_corpora[max_desvio_idx]} mostra maior variabilidade no tamanho das sentenças, \"\n",
    "        f\"com desvio padrão de {stats[max_desvio_idx]['desvio']:.1f} tokens.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    arquivo_latex.write(\n",
    "        \"\\\\subsection{Interpretação dos Histogramas}\\n\"\n",
    "        \"Os histogramas mostram a distribuição do número de tokens por sentença em cada corpus. \"\n",
    "        \"As linhas verticais indicam a média e a mediana, permitindo visualizar:\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "        \"\\\\item A forma geral da distribuição e sua simetria\\n\"\n",
    "        \"\\\\item A concentração de sentenças em determinados tamanhos\\n\"\n",
    "        \"\\\\item A presença de outliers (sentenças muito curtas ou muito longas)\\n\"\n",
    "        \"\\\\item A relação entre média e mediana, indicando possível assimetria\\n\"\n",
    "        \"\\\\end{itemize}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Inserir gráfico\n",
    "    arquivo_latex.write(salvar_grafico_e_gerar_latex(caminho_grafico_base, \n",
    "        \"Distribuição Comparativa do Tamanho das Sentenças\"))\n",
    "    \n",
    "    arquivo_latex.write(\"\\\\clearpage\\n\")\n",
    "    \n",
    "    return {\n",
    "        'estatisticas': stats,\n",
    "        'tokens_por_sentenca': tokens_por_sentenca  # Corrigido aqui\n",
    "    }\n",
    "\n",
    "def gerar_relatorio_latex(corpora_data, nomes_corpora, arquivo_saida_latex):\n",
    "    \"\"\"\n",
    "    Gera um relatório LaTeX comparativo para múltiplos corpora\n",
    "    \n",
    "    Args:\n",
    "        corpora_data: Lista com os dados CONLLU dos corpora\n",
    "        nomes_corpora: Lista com os nomes dos corpora\n",
    "        arquivo_saida_latex: Caminho do arquivo LaTeX de saída\n",
    "    \"\"\"\n",
    "    # Caminhos base para os gráficos\n",
    "    caminhos_graficos = {\n",
    "        'pos': \"distribuicao_frequencia_tags\",\n",
    "        'comprimento': \"distribuicao_comprimento_tokens\",\n",
    "        'sentenca': \"distribuicao_tags_sentenca\",\n",
    "        'jensen_shannon': \"distribuicao_jensen_shannon\",\n",
    "        'diversidade': \"diversidade_lexical\",\n",
    "        'ks': \"distribuicao_ks\",\n",
    "        'freq_sentenca': \"distribuicao_frequencia_por_sentenca\"\n",
    "    }\n",
    "\n",
    "    with open(arquivo_saida_latex, 'w', encoding='utf-8') as arquivo_latex:\n",
    "        # Cabeçalho do arquivo LaTeX\n",
    "        arquivo_latex.write(\n",
    "            \"\\\\documentclass{article}\\n\"\n",
    "            \"\\\\usepackage[utf8]{inputenc}\\n\"\n",
    "            \"\\\\usepackage[T1]{fontenc}\\n\"\n",
    "            \"\\\\usepackage[brazil]{babel}\\n\"\n",
    "            \"\\\\usepackage{graphicx}\\n\"\n",
    "            \"\\\\usepackage{float}\\n\"\n",
    "            \"\\\\usepackage{array}\\n\"\n",
    "            \"\\\\begin{document}\\n\"\n",
    "        )\n",
    "        \n",
    "        # Título\n",
    "        titulo = \"Análise Estatística Comparativa:\\\\\\\\%s\" % \" vs. \".join(nomes_corpora)\n",
    "        arquivo_latex.write(f\"\\\\title{{{titulo}}}\\n\\\\maketitle\\n\")\n",
    "        \n",
    "        # Análises\n",
    "        analise_frequencia_pos(\n",
    "            corpora_data, \n",
    "            nomes_corpora, \n",
    "            caminhos_graficos['pos'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        analise_comprimento_tokens(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['comprimento'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        analise_tags_por_sentenca(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['sentenca'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        analise_diversidade_lexical(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['diversidade'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        analise_jensen_shannon(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['jensen_shannon'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        teste_ks(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['ks'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        analise_frequencia_por_sentenca(\n",
    "            corpora_data,\n",
    "            nomes_corpora,\n",
    "            caminhos_graficos['freq_sentenca'],\n",
    "            arquivo_latex\n",
    "        )\n",
    "        \n",
    "        arquivo_latex.write(\"\\\\end{document}\")\n",
    "\n",
    "    print(f\"Relatório LaTeX salvo como {arquivo_saida_latex}.\")\n",
    "\n",
    "# Uso da função com os três corpora\n",
    "corpora_data = [dados_conllu1, dados_conllu2, dados_conllu3]\n",
    "nomes_corpora = [Dantes_Manual, Dantes_Automatizado, Dantes_Large]\n",
    "\n",
    "gerar_relatorio_latex(corpora_data, nomes_corpora, \"relatorio_comparativo.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
